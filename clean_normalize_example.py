"""
Script d'exemple pour le nettoyage et la normalisation des datasets MAPAQ.

Ce script d√©montre l'utilisation compl√®te du pipeline de nettoyage
et de normalisation des donn√©es d'inspection des restaurants.

Author: Grace Mandiangu
Date: November 25, 2025
"""

import pandas as pd
import numpy as np
from pathlib import Path
import logging

from src.data_ingest import MAPAQDataIngestor
from src.data_cleaner import DataCleaner

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


def create_sample_data():
    """
    Cr√©e un dataset d'exemple avec des donn√©es non nettoy√©es.
    
    Returns:
        DataFrame avec des donn√©es brutes simul√©es
    """
    logger.info("Cr√©ation d'un dataset d'exemple...")
    
    # Donn√©es d'exemple avec probl√®mes typiques
    data = {
        'Nom Restaurant': [
            '  Sushi Express  ',
            'Pizza Palace',
            'BBQ King',
            'Pizza Palace',  # Doublon
            'Caf√© Bistro',
            '  Bakery Delight',
            'Fast Burger',
            None,  # Valeur manquante
            'Thai Garden',
            'Steakhouse Premium'
        ],
        'Adresse': [
            '123 Rue Saint-Laurent',
            '456 Av. Mont-Royal  ',
            '789 Boul. Ren√©-L√©vesque',
            '456 Av. Mont-Royal',  # Doublon
            '321 Rue Sherbrooke',
            '654 Rue Sainte-Catherine  ',
            '987 Boul. D√©carie',
            '111 Rue Principale',
            '222 Av. du Parc',
            '333 Rue Crescent'
        ],
        'Ville': [
            'MONTREAL',
            'montreal',
            'Montreal',
            'montreal',
            'Quebec',
            'LAVAL',
            'Montreal',
            'Gatineau',
            'Montreal',
            'Montreal'
        ],
        'Type Cuisine': [
            'Sushi',
            'Italian',
            'BBQ',
            'Italian',
            'French',
            'Bakery',
            'Fast Food',
            'Other',
            'Asian',
            'Steakhouse'
        ],
        'Nombre Employes': [
            10,
            15,
            8,
            15,
            12,
            5,
            20,
            np.nan,  # Valeur manquante
            7,
            18
        ],
        'Infractions': [
            2,
            0,
            1,
            0,
            0,
            1,
            3,
            1,
            0,
            1
        ],
        'Taille Cuisine': [
            35.5,
            50.0,
            40.0,
            50.0,
            45.5,
            25.0,
            60.0,
            30.0,
            28.5,
            55.0
        ],
        'Date Inspection': [
            '2024-01-15',
            '2024-02-20',
            '2024-03-10',
            '2024-02-20',
            '2024-04-05',
            '2024-05-12',
            '2024-06-18',
            '2024-07-22',
            '2024-08-30',
            '2024-09-15'
        ]
    }
    
    df = pd.DataFrame(data)
    logger.info(f"Dataset cr√©√© avec {len(df)} lignes et {len(df.columns)} colonnes")
    
    return df


def analyze_data_quality(df: pd.DataFrame, title: str = "Dataset"):
    """
    Analyse la qualit√© des donn√©es.
    
    Args:
        df: DataFrame √† analyser
        title: Titre pour l'affichage
    """
    print(f"\n{'='*60}")
    print(f"ANALYSE DE QUALIT√â - {title}")
    print(f"{'='*60}")
    
    print(f"\nüìä Dimensions: {df.shape[0]} lignes √ó {df.shape[1]} colonnes")
    
    print(f"\nüìã Colonnes:")
    for col in df.columns:
        print(f"  - {col}")
    
    print(f"\n‚ùå Valeurs manquantes:")
    missing = df.isnull().sum()
    for col, count in missing.items():
        if count > 0:
            percentage = (count / len(df)) * 100
            print(f"  - {col}: {count} ({percentage:.1f}%)")
    
    print(f"\nüîÑ Doublons: {df.duplicated().sum()}")
    
    print(f"\nüìà Statistiques num√©riques:")
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    if len(numeric_cols) > 0:
        print(df[numeric_cols].describe().round(2))


def clean_and_normalize_pipeline():
    """
    Pipeline complet de nettoyage et normalisation.
    """
    print("\n" + "="*80)
    print("üßπ PIPELINE DE NETTOYAGE ET NORMALISATION DES DONN√âES MAPAQ")
    print("="*80)
    
    # 1. Cr√©er des donn√©es d'exemple
    print("\nüì• √âTAPE 1: Cr√©ation des donn√©es d'exemple")
    df_raw = create_sample_data()
    
    # Analyser les donn√©es brutes
    analyze_data_quality(df_raw, "DONN√âES BRUTES")
    
    # 2. Initialiser le nettoyeur
    print("\nüîß √âTAPE 2: Initialisation du DataCleaner")
    cleaner = DataCleaner()
    
    # 3. Nettoyer les donn√©es
    print("\nüßπ √âTAPE 3: Nettoyage des donn√©es")
    df_clean = cleaner.clean_dataset(df_raw)
    
    # Analyser les donn√©es nettoy√©es
    analyze_data_quality(df_clean, "DONN√âES NETTOY√âES")
    
    # 4. G√©n√©rer un rapport de nettoyage
    print("\nüìä √âTAPE 4: Rapport de nettoyage")
    report = cleaner.get_cleaning_report(df_raw, df_clean)
    
    print(f"\n{'='*60}")
    print("RAPPORT DE NETTOYAGE")
    print(f"{'='*60}")
    print(f"Lignes initiales:    {report['lignes_initiales']}")
    print(f"Lignes finales:      {report['lignes_finales']}")
    print(f"Lignes supprim√©es:   {report['lignes_supprimees']}")
    print(f"Taux de r√©tention:   {report['taux_retention']}%")
    
    # 5. Normalisation avanc√©e
    print("\nüîÑ √âTAPE 5: Normalisation avanc√©e")
    df_normalized = advanced_normalization(df_clean)
    
    # 6. Sauvegarder les donn√©es nettoy√©es
    print("\nüíæ √âTAPE 6: Sauvegarde des donn√©es")
    output_dir = Path("data/cleaned")
    output_dir.mkdir(parents=True, exist_ok=True)
    
    output_path = output_dir / "restaurants_cleaned.csv"
    cleaner.save_cleaned_data(df_normalized, str(output_path))
    
    print(f"\n‚úÖ Donn√©es nettoy√©es sauvegard√©es: {output_path}")
    
    # 7. Afficher un aper√ßu final
    print("\nüëÄ APER√áU DES DONN√âES FINALES:")
    print(df_normalized.head(10).to_string())
    
    return df_normalized


def advanced_normalization(df: pd.DataFrame) -> pd.DataFrame:
    """
    Normalisation avanc√©e des donn√©es.
    
    Args:
        df: DataFrame √† normaliser
        
    Returns:
        DataFrame normalis√©
    """
    df = df.copy()
    
    # Normaliser les noms de villes
    if 'ville' in df.columns:
        df['ville'] = df['ville'].str.upper().str.strip()
        logger.info("Villes normalis√©es en majuscules")
    
    # Normaliser les types de cuisine
    if 'type_cuisine' in df.columns:
        df['type_cuisine'] = df['type_cuisine'].str.title().str.strip()
        logger.info("Types de cuisine normalis√©s")
    
    # Convertir les dates
    if 'date_inspection' in df.columns:
        df['date_inspection'] = pd.to_datetime(df['date_inspection'])
        logger.info("Dates converties en format datetime")
    
    # Remplir les valeurs manquantes num√©riques
    numeric_cols = df.select_dtypes(include=[np.number]).columns
    for col in numeric_cols:
        if df[col].isnull().any():
            median_val = df[col].median()
            df[col].fillna(median_val, inplace=True)
            logger.info(f"Valeurs manquantes de '{col}' remplies avec la m√©diane: {median_val}")
    
    # Cr√©er des colonnes d√©riv√©es
    if 'nombre_employes' in df.columns:
        df['categorie_taille'] = pd.cut(
            df['nombre_employes'],
            bins=[0, 5, 15, 100],
            labels=['Petit', 'Moyen', 'Grand']
        )
        logger.info("Colonne 'categorie_taille' cr√©√©e")
    
    if 'infractions' in df.columns:
        df['niveau_conformite'] = df['infractions'].apply(
            lambda x: 'Excellent' if x == 0 else 'Bon' if x <= 1 else '√Ä am√©liorer'
        )
        logger.info("Colonne 'niveau_conformite' cr√©√©e")
    
    return df


def main():
    """Fonction principale."""
    try:
        # Ex√©cuter le pipeline complet
        df_final = clean_and_normalize_pipeline()
        
        print("\n" + "="*80)
        print("‚úÖ PIPELINE TERMIN√â AVEC SUCC√àS!")
        print("="*80)
        print(f"\nDataset final: {len(df_final)} lignes √ó {len(df_final.columns)} colonnes")
        print(f"Fichier sauvegard√©: data/cleaned/restaurants_cleaned.csv")
        
    except Exception as e:
        logger.error(f"Erreur lors de l'ex√©cution: {str(e)}")
        raise


if __name__ == "__main__":
    main()
