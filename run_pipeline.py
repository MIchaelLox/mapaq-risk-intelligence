"""
Script d'exÃ©cution du pipeline de donnÃ©es MAPAQ Risk Intelligence.

Ce script permet d'exÃ©cuter le pipeline complet de traitement des donnÃ©es
avec une interface en ligne de commande conviviale.

Author: Grace Mandiangu
Date: November 30, 2025
"""

import sys
import os
from pathlib import Path
import logging
import argparse

# Ajouter le rÃ©pertoire src au path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

from src.data_pipeline import DataPipeline

# Configuration du logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def print_banner():
    """Affiche la banniÃ¨re du pipeline."""
    banner = """
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘                                                              â•‘
    â•‘        ğŸ”„ MAPAQ RISK INTELLIGENCE DATA PIPELINE              â•‘
    â•‘                                                              â•‘
    â•‘        Pipeline Complet de Traitement des DonnÃ©es           â•‘
    â•‘                                                              â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    ğŸ“Š Ã‰tapes du Pipeline:
    
    1ï¸âƒ£  Ingestion       - Chargement des donnÃ©es brutes
    2ï¸âƒ£  Validation      - VÃ©rification des rÃ¨gles mÃ©tier
    3ï¸âƒ£  Nettoyage       - Suppression doublons, normalisation
    4ï¸âƒ£  Transformation  - Enrichissement et features
    5ï¸âƒ£  Sauvegarde      - Export CSV/JSON + Rapport
    
    ğŸ‘¤ DÃ©veloppÃ© par: Grace Mandiangu
    ğŸ“… Version: 1.0
    
    â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """
    print(banner)


def parse_arguments():
    """
    Parse les arguments de la ligne de commande.
    
    Returns:
        Arguments parsÃ©s
    """
    parser = argparse.ArgumentParser(
        description='Pipeline de traitement des donnÃ©es MAPAQ',
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    
    parser.add_argument(
        'input_file',
        type=str,
        help='Chemin du fichier de donnÃ©es brutes (CSV)'
    )
    
    parser.add_argument(
        '-o', '--output',
        type=str,
        default=None,
        help='Nom de base pour les fichiers de sortie (optionnel)'
    )
    
    parser.add_argument(
        '-c', '--config',
        type=str,
        default=None,
        help='Chemin du fichier de configuration JSON (optionnel)'
    )
    
    parser.add_argument(
        '--status',
        action='store_true',
        help='Afficher le statut du pipeline sans exÃ©cution'
    )
    
    return parser.parse_args()


def check_input_file(filepath: str) -> bool:
    """
    VÃ©rifie que le fichier d'entrÃ©e existe.
    
    Args:
        filepath: Chemin du fichier
        
    Returns:
        True si le fichier existe, False sinon
    """
    if not Path(filepath).exists():
        logger.error(f"âŒ Fichier introuvable: {filepath}")
        return False
    
    if not filepath.endswith('.csv'):
        logger.warning(f"âš ï¸  Le fichier n'est pas un CSV: {filepath}")
    
    return True


def display_pipeline_status(pipeline: DataPipeline):
    """
    Affiche le statut du pipeline.
    
    Args:
        pipeline: Instance du pipeline
    """
    status = pipeline.get_pipeline_status()
    
    print("\nğŸ“Š STATUT DU PIPELINE")
    print("=" * 60)
    
    print("\nğŸ“ Configuration:")
    for key, value in status['config'].items():
        print(f"  â€¢ {key}: {value}")
    
    print("\nğŸ“‚ RÃ©pertoires:")
    for dir_name, exists in status['directories_exist'].items():
        status_icon = "âœ…" if exists else "âŒ"
        print(f"  {status_icon} {dir_name}: {'Existe' if exists else 'Manquant'}")
    
    print("\n" + "=" * 60)


def main():
    """Fonction principale."""
    try:
        print_banner()
        
        # Parser les arguments
        args = parse_arguments()
        
        # Initialiser le pipeline
        logger.info("Initialisation du pipeline...")
        pipeline = DataPipeline(config_path=args.config)
        
        # Mode statut uniquement
        if args.status:
            display_pipeline_status(pipeline)
            return 0
        
        # VÃ©rifier le fichier d'entrÃ©e
        if not check_input_file(args.input_file):
            return 1
        
        logger.info(f"ğŸ“‚ Fichier d'entrÃ©e: {args.input_file}")
        
        if args.output:
            logger.info(f"ğŸ“ Nom de sortie: {args.output}")
        
        # ExÃ©cuter le pipeline
        print("\nğŸš€ DÃ©marrage du pipeline...\n")
        
        report = pipeline.run_full_pipeline(
            input_file=args.input_file,
            output_name=args.output
        )
        
        # Afficher le rÃ©sumÃ©
        print("\n" + "=" * 70)
        print("ğŸ“Š RÃ‰SUMÃ‰ DU PIPELINE")
        print("=" * 70)
        print(f"\nâ±ï¸  DurÃ©e: {report['pipeline_info']['duration_seconds']} secondes")
        print(f"\nğŸ“ˆ Flux de donnÃ©es:")
        print(f"  â€¢ Lignes brutes:      {report['data_flow']['raw_rows']}")
        print(f"  â€¢ Lignes validÃ©es:    {report['data_flow']['validated_rows']}")
        print(f"  â€¢ Lignes nettoyÃ©es:   {report['data_flow']['cleaned_rows']}")
        print(f"  â€¢ Lignes finales:     {report['data_flow']['final_rows']}")
        print(f"  â€¢ Taux de rÃ©tention:  {report['data_flow']['retention_rate']}%")
        
        if report['validation']['issues']:
            print(f"\nâš ï¸  ProblÃ¨mes dÃ©tectÃ©s: {len(report['validation']['issues'])}")
            for issue in report['validation']['issues'][:3]:  # Afficher max 3
                print(f"  â€¢ {issue['column']}: {issue['invalid_count']} valeurs invalides")
        
        print(f"\nâœ… Pipeline terminÃ© avec succÃ¨s!")
        print(f"ğŸ“ Fichiers gÃ©nÃ©rÃ©s dans: data/processed/ et data/reports/")
        print("=" * 70 + "\n")
        
        return 0
    
    except KeyboardInterrupt:
        logger.info("\n\nğŸ›‘ Pipeline interrompu par l'utilisateur")
        return 130
    
    except Exception as e:
        logger.error(f"\nâŒ Erreur lors de l'exÃ©cution du pipeline: {str(e)}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    sys.exit(main())
